<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>软院云平台文档</title><link>https://scs.buaa.edu.cn/doc/</link><description>Recent content on 软院云平台文档</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://scs.buaa.edu.cn/doc/index.xml" rel="self" type="application/rss+xml"/><item><title>Lab01 RAID 阵列</title><link>https://scs.buaa.edu.cn/doc/ns-labs/table-of-contents/raid/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://scs.buaa.edu.cn/doc/ns-labs/table-of-contents/raid/</guid><description>Lab01 RAID阵列 # 本指导书是实验过程的一个示例，供不熟悉实验环境的同学参考，无需严格按照指导书中的步骤来进行实验 :)
实验内容 # 本实验通过软件 RAID 管理磁盘：
通过工具查看磁盘列表 [仅Windows] C 盘扩展卷，检查其它磁盘是否联机，联机并初始化磁盘 [仅Ubuntu] 使用LVM扩展根目录/的容量 创建RAID阵列，测试读写文件并模拟磁盘损坏，观察有什么情况发生，数据是否损坏或者丢失？ 尝试RAID 0 尝试RAID 1 尝试RAID 5 [选做] 控制变量，测试RAID阵列的读写速率，并结合理论分析实验结果 [选做] 自行设计与扩展，体会 RAID 0 1 5 10 等方案下，在遇到磁盘损坏故障、冗余备份的效果等 [选做] 思考题： 为什么及在什么条件下选择用 RAID RAID &amp;amp; 分布式存储 &amp;amp; 集中存储的区别 其中，选做的题目不计入本实验的总得分，仅额外加分
实验报告模板分别是lab01_win.md和lab01_ubuntu.md，供参考使用，最后请将实验报告按 lab01-学号-姓名.pdf 的命名格式提交
实验准备 # Windows下连接Windows 10虚拟机 # 使用系统自带的“远程桌面连接”即可
MacOS下连接Windows 10虚拟机 # 使用Microsoft Remote Desktop连接，云平台课程资源页提供该软件的下载
Windows下连接Ubuntu虚拟机 # 一般来讲，Windows 10（及以上）自带的cmd.exe都自带ssh client，打开cmd后直接ssh foo@x.x.x.x即可登录
为了更好的使用体验，推荐下载使用 Windows Terminal
当然，你也可以使用 termius 或者其他工具（如 Xshell等）进行多个ssh连接的管理</description></item><item><title>Lab02 虚拟化实验</title><link>https://scs.buaa.edu.cn/doc/ns-labs/table-of-contents/virtualization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://scs.buaa.edu.cn/doc/ns-labs/table-of-contents/virtualization/</guid><description>Lab02 虚拟化实验 # 实验目标 # 实施计算虚拟化，安装配置环境，熟悉计算虚拟化的概念，理解基本操作，掌握基础知识。 理解集中管理对于虚拟化的作用，通过部署集中vCenter体验集群的设置，分布式交换机的设置，了解主机从不同网络进行迁移的实际需求。 实验内容 # 按照实验指南的指导，完成实验。 按照实验报告模板，撰写实验报告，将重要的实验步骤截图，填入实验报告中，并回答相应问题。 本次实验以小组形式进行，虚拟机已分发至每组第一位同学的账户中，每组一台虚拟机，实验报告每个人都需要提交，同组的实验报告内容可以一致
请在云平台作业提交截止时间之前，将作业提交到云平台，命名为：lab02-学号-姓名.pdf的格式。
Hypervisor # 我们知道，一台计算机一般有以下的结构：
操作系统负责管理硬件资源（CPU，内存，硬盘等），并向上提供相应的系统调用，供具体的应用程序使用。
而我们平常提到的操作系统的虚拟化，本质上就是要模拟出一套硬件（包括虚拟CPU，虚拟内存，虚拟硬盘等），然后在这一套虚拟的硬件的基础上部署客户操作系统。客户操作系统完全不需要做任何修改，即可在这个“虚拟的机器”中顺利执行。但客户操作系统的运行结果（比如接收键盘输入，输出图像和声音等），最终都是要靠原始的“实实在在”的硬件（物理机）来完成的。也就是说，需要有那么一个结构，能够将这个“虚拟的机器”的行为翻译到物理机的行为（比如将虚拟CPU的指令翻译到物理机的CPU指令）。负责做这件事情的结构被称为Hypervisor，又称为虚拟机监控器（virtual machine monitor，缩写为 VMM）。
根据工作方式的不同，Hypervisor分为以下两种。
第一种是我们比较熟悉的情况，本质上就是在主操作系统（Host Operating System）上安装了一个虚拟化软件，它来负责充当虚拟机的管理者，并通过主操作系统的系统调用来完成对物理机硬件的使用。VMware Workstation、Virtual Box、Qemu等都属这类虚拟化软件。除了这个虚拟化软件之外，主操作系统上还会运行其他“正常”的应用程序，比如，你在用VMware Workstation的同时还能听歌聊天等。
第二种Hypervisor则直接舍弃了主操作系统（因为毕竟隔着一层，性能会有损失），而是直接把Hypervisor部署在硬件上。在这种情况下，物理机变成了更纯粹的“为虚拟化而生”的机器。Hypervisor能够直接与硬件沟通，其实在某种程度上也承担了主操作系统的角色（管理硬件），因此，我们也可以把这种Hypervisor看作是一种为虚拟化特制的操作系统。这其中典型的就是VMware ESXi。
因为我们不可能要求每位同学都制备一套硬件来安装学习VMware ESXi，所以需要首先使用VMware Workstation来模拟出一套硬件。但VMware Workstation仅仅起一个前置作用，在实际的实验中并不会涉及到。请大家首先理清这层关系。
实验指南 # 0. 安装VMware Workstation # 使用分配的虚拟机的桌面上的安装包安装即可。
安装完成后需重启机器。
打开VMware Workstation时， 选择试用即可。
1. 安装VMware ESXi # 使用桌面上的ESXi镜像VMware-VMvisor-Installer-6.7.0.update03-19898906.x86_64-DellEMC_Customized-A18.iso创建虚拟机。
注意选择客户操作系统的类型。
虚拟机创建完成后，直接打开电源即可启动ESXi操作系统的安装流程，这一过程可能需要等待较长时间。
安装流程中总是保持默认选项即可，其中设置的root密码应至少包含字母、数字和特殊符号，并且请务必牢记设置的root密码。
在此流程中，可能需要使用使用到某些快捷键，这些快捷键可能会首先被你本机的操作系统捕获，在本机的系统设置中暂时屏蔽该快捷键即可。
安装完成后，可以看到如下界面。
可以看到，ESXi系统获得了一个IPv4地址192.168.80.128，并且这个地址是通过DHCP的方式获得的。这里用到的DHCP服务器其实是VMware Workstation内置的。也就是说，192.168.80.128这个地址只有在安装VMware Workstation的机器上才是有效的。
2. 访问ESXi # 可以直接使用浏览器访问ESXi。访问的地址就是ESXi的地址，用户名和密码与vSphere Client的相同。
如下图所示，可以为ESXi分配许可证。
可用的KEY：
0A65P-00HD0-3Z5M1-M097M-22P7H 3. 观察和体验vSphere Client提供的功能 # Client侧界面主要包含导航器、主体内容和任务事件这三部分。</description></item><item><title>Lab03 Ceph存储集群实践</title><link>https://scs.buaa.edu.cn/doc/ns-labs/table-of-contents/ceph/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://scs.buaa.edu.cn/doc/ns-labs/table-of-contents/ceph/</guid><description>Lab03 Ceph 存储集群实践 # 实验目的 # 了解 Ceph 存储的基本工作原理
建立对分布式存储的初步认识
实验说明 # 按照实验指南的指导，完成实验。
按照实验报告模板，撰写实验报告，将重要的实验步骤截图，填入实验报告中，并回答相应问题。
本次实验由小组内成员分工完成，虚拟机已分发至每组第一位同学的账户中，每组一台虚拟机，实验报告每个人都需要提交，同组的实验报告内容可以一致
本次实验的分数构成如下：
必做（7分）： Ceph部署 三选一（3分）： Ceph Filesystem Ceph RGW 对象存储 Ceph RBD 其中，Ceph Filesystem、Ceph RGW、Ceph RBD任选其一完成即可得到“三选一”部分的分数，多做没有额外的加分。如果你想在网络存储课程上投入更多的精力，欢迎参与课程设计申优答辩。
在实验过程中，在执行每一条命令之前请务必搞清楚它是用来干啥的，执行后会有什么结果。
实验中遇到的困难请及时在课程微信群中抛出。 除本指导书外，实验的主要的参考资料还包括： Ceph 官方文档、 Ceph 部署指南、互联网上的技术博客等。
请在云平台作业提交截止时间之前，将作业提交到云平台，命名为：lab03-学号-姓名.pdf的格式。
概述 # Ceph(读音 /ˈsɛf/) 是一个分布式的存储集群。什么是分布式存储？我们为什么需要它？
试想，你在搭建了一个网站对外提供服务。用户在使用网站的过程中会存储大量的数据，网站运行过程中也会产生大量的日志信息。
最初，你将网站部署在一个装有 500G 硬盘的服务器上。随着时间的流逝，500G 的硬盘逐渐被填满。现在你有两种选择。
纵向拓展。在服务器上加装硬盘，甚至你可以使用 LVM 将硬盘无缝拓展到原来的文件系统中，上层应用和用户根本看不出来有任何差别。但随着数据量的进一步积累，加装的硬盘还会被填满。即使你将服务器的硬盘槽位都插满，最终还是无法解决数据量逐渐增大的问题。数据是无限的，一台机器能承受的数据量总是有限的，氪金也无法解决这个问题。
横向拓展。买一台新的服务器，用网线把它和原来的服务器连起来，把原来的服务器存不下的数据存储到这台新的服务器上。当需要使用到这些数据时，再从新的服务器上取出来。当第二台服务器被填满后，再添加新的服务器。
第二种看起来是最可行的方法：随着业务的扩展，继续加机器就可以了。这种由多台网络互通的机器组成的存储系统即可被理解为“分布式存储系统”。
但随着机器数量的增加，整个系统的复杂度也在上升。新的多机器系统会表现出与原来的单机系统很多不同的特性，会带来更多的问题，比如：
如何划分数据？也就是说，如何决定网站接收的某份数据该存储到哪台机器上？每台机器的存储容量可能不同，存储性能也可能不同，如何平衡每台机器的存储容量？
如何获取数据？我们将数据保存在不同的机器上时，通常保存的不是一个完整的文件，而是经过一个个切分后的数据块，每个数据块可能保存在不同的机器上。当获取数据时，我们需要知道要获取的文件包含哪些数据块，每个数据块存放在哪台机器的哪个位置。随着机器数量和数据量的增加，这不是一个简单的任务。
随着机器数量的增加，系统发生故障的概率也在增加。仅对硬盘而言，我们假设每块硬盘在一年中发生故障的概率是 1%，对于普通消费者而言，这似乎不是什么问题，这种故障可能在硬盘的整个使用周期内都不会发生；但对于一个包含几百块硬盘的存储系统来说，这意味着几乎每天都会有若干块硬盘发生故障，而每块硬盘的故障都有可能造成系统的宕机和数据损失。因此，分布式存储系统必须有较强的容错能力，能够在一定数量的机器崩溃时，仍能对外提供服务。
……
上面这些问题，正是 Ceph 这类分布式存储系统所要解决的问题。简单来说，Ceph 是一个能将大量廉价的存储设备统一组织起来，并对外提供统一的服务接口的，提供分布式、横向拓展、高度可靠性的存储系统。
对分布式系统感兴趣的同学，可以趁下学期或大四空闲的时候听一下 MIT 6.824的课程，并尽量完成它的全部实验。
在互联网上搜索“MIT 6.824”能得到大量的资料，比如，B 站上有 翻译好的熟肉。</description></item><item><title>容器与Docker综合实验</title><link>https://scs.buaa.edu.cn/doc/cloud-labs/cloud/container_docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://scs.buaa.edu.cn/doc/cloud-labs/cloud/container_docker/</guid><description>容器与Docker综合实验 # 💡 文档中对各个概念的定义和阐述并不是严谨的，文档中用语尽量通俗易懂，大多数只是为了让同学们明白这个概念大致在说什么东西，能在头脑中有个感性的认识（这对知识的掌握和学习非常重要）。概念的严格定义还请参考对应的官方文档。 💡 容器和Docker的内容非常繁杂，实验文档不可能面面俱到，因此很多内容以链接的形式给出。请同学们在阅读文档本身的同时，不要忘记学习链接中指出的内容。 💡 同学们在执行命令时，一定要认真阅读命令的输出和log，通过阅读这些输出，你很容易了解你所执行的命令具体执行了哪些操作，这非常有助于理解其背后的运行原理。 💡 目前流行的绝大多数容器运行时都是用Go语言编写，著名的容器编排工具Kubernetes也是用Go语言编写的，基于Docker和Kubernetes建立起来的整个云计算生态中的绝大部分项目也都是用Go语言实现的。因此，如果想深入了解和学习云计算相关内容的话，建议同学们学习和掌握Go语言。当然，这并不是本次实验和这门课的要求:) 注意事项
本次分配的机器的账户和密码为： buaa: &amp;amp;shieshuyuan21 务必首先修改机器的root和buaa账户的密码
请务必阅读 虚拟机使用说明。
分配的虚拟机中，已经安装了Docker，无需重复安装；并设置了Docker镜像地址（该地址指向校内地址），理论上docker.io中的镜像不用联网即可拉取。例如可以直接在虚拟机上docker pull nginx。
实验目的 # 理解容器的概念，了解实现容器所使用的的底层技术，理解容器与虚拟机的区别
理解容器与Docker之间的关系
掌握Docker的基本使用方法和常见命令，可以使用Dockerfile构建镜像
实验要求 # 请参考本实验文档，并查阅相关资料，回答以下问题并完整记录实验过程：
数据持久化。容器是 “一次性的” 和 “脆弱的”（请大家务必牢记容器这一特性），容器很容易因为各种原因被kill（如资源不足等等）。而容器产生的数据文件是和容器绑定在一起的，当容器被删除时，这些数据文件也会被删除，这是我们不想看到的。
比如，我们在机器上启动了一个mysql容器，在写入了一些重要数据后，因为某种原因该容器被意外删除了。此时即使重新启动一个mysql容器也找不会之前的数据了。请结合实验文档中的内容和查阅相关资料，讨论应该通过何种方式启动容器来避免出现这一问题？你能得出几种方案？每种方案的优劣如何？并请分别使用这些方案模拟mysql容器 创建 - 写入数据 - 销毁 - 重新创建 - 重新读到之前写入的数据 的场景，以证明方案的有效性。
请从ubuntu镜像开始，构建一个新的包含Nginx服务的ubuntu镜像，并修改Nginx主页内容为你的学号，请分别使用docker commit 和 Dockerfile两种方式完成， 并将这个新构建的镜像推送到软院的image registry中。这个镜像推送的地址应该是 harbor.scs.buaa.edu.cn/&amp;lt;你的学号&amp;gt;/ubuntu-nginx:${TAG}，其中，使用docker commit构建的镜像的TAG为dockercommit；使用Dockerfile构建的镜像的TAG为 dockerfile。
在测评时，助教会分别对你push的两个镜像执行以下命令（假设镜像名称为example_image_name）：
docker run -d -p 8899:80 example_image_name; sleep 5; curl localhost:8899 请保证上述命令的输出中包含你的学号。
Hint:
harbor.scs.buaa.edu.cn 这个网页可以打开
harbor.scs.buaa.edu.cn 的用户名为你的学号，默认密码为Newpass@2021</description></item><item><title>操作系统</title><link>https://scs.buaa.edu.cn/doc/ns-labs/resources/os/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://scs.buaa.edu.cn/doc/ns-labs/resources/os/</guid><description> 操作系统 # 常见操作系统 ISO 镜像可至官网、 MSDN，我告诉你、 Next, ITELLYOU 等网站上去下载。
Windows Server 2019 # ED2K 下载：ed2k://|file|cn_windows_server_2019_updated_july_2020_x64_dvd_2c9b67da.iso|5675251712|19AE348F0D321785007D95B7D2FAF320|/
使用 KMS 激活方式如下：
# 使用管理员身份打开PowerShell DISM /online /Set-Edition:ServerDatacenter /ProductKey:WMDGN-G9PQG-XVVXX-R3X43-63DFG /AcceptEula # 打开 CMD (管理员) slmgr.vbs /ipk WMDGN-G9PQG-XVVXX-R3X43-63DFG slmgr.vbs /skms kms.teevee.asia slmgr.vbs /ato</description></item><item><title>云计算课程设计</title><link>https://scs.buaa.edu.cn/doc/cloud-labs/cloud/cloud_course_design/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://scs.buaa.edu.cn/doc/cloud-labs/cloud/cloud_course_design/</guid><description> 云计算课程设计 # 背景 # 当今时代是云原生的时代。
容器化带来的优势 # 在之前的《容器与Docker》的实验中，我们从“隔离不同的应用程序”入手，介绍了引入容器的必然性。容器之间这种相互隔离的特性为使它非常便于进行弹性伸缩和迁移部署。
各位试想一下自己之前部署一个应用的过程，通常分为这么几个步骤：
编译源代码，得到编译产物（你可能需要根据不同的部署目标编译多个不同平台的编译产物，比如在macOS和Windows上开发，却需要编译Linux目标平台的产物） 在目标机器上安装运行时环境（对于部分类型的应用程序来说，这一步可以省略，如大部分Go、Rust等编写的应用） 将编译产物传送到目标机器 设置程序运行时需要的环境变量、配置文件等（大多数情况下至少需要维护开发时和运行时两种不同的配置文件和环境变量） 启动应用程序 如果是需要长期稳定运行的程序，还需要配置程序作为守护进程启动（可能需要编写systemd配置文件等） 而对于以容器形式部署的应用来说，只需要：
编写Dockerfile（这里会包含进程在运行时需要使用的环境变量和配置文件等） 根据Dockerfile构建镜像 推送镜像到目标机器，然后使用docker run启动容器 整个过程流畅而优雅，并且因为需要操作的步骤很少，所以会有更低的出错的可能（在传统的部署过程中，敲错一行命令导致部署失败是常有的事）。而且，更进一步地：
有些时候，我们将机器A上的应用迁移到机器B上时，如果使用传统部署方式，则很可能需要将1至6这几个步骤重复走一遍；而如果使用容器部署方式，只需要在机器B上拉取机器A中使用的镜像，重新启动容器即可。 有些时候，我们可能需要在同一台机器上部署和管理一个应用的多个不同的实例（如对于单进程应用，出于负载均衡，充分榨干机器性能的需要），如果使用传统部署方式，很可能需要为每个需要部署的实例修改不同的配置，并手动开启或关闭这多个实例；而如果使用容器部署的方式，则只需修改docker run的参数，对于启动的多个实例，可以轻松地使用docker本身提供的工具进行管理。 大多数情况下，一个应用程序往往会依赖若干个不同的外部服务。比如一个Java编写的后端服务，可能需要依赖数据库、对象存储等服务。这些外部服务的部署和配置在部署应用时也是一个很让人头疼的事情。而对于容器的部署方式，这些外部服务，诸如数据库、对象存储等，完全也可以实现容器化，它们的部署也可以使用基于容器的方式进行（相信各位在上次实验中已经体会到了使用容器的方式部署MySQL服务的便利性）。 微服务与容器 # 相信很多同学都接触或者实践过微服务架构（比如Spring Cloud之类的）。微服务，简单来讲就是说将原来的整个软件系统，拆分成不同的模块，每个模块对外都表现为一个独立的系统（它们可以独立进行开发、测试和部署），每个模块对外暴露规划好的接口，不同模块之间通过某种协议（一般是原生的HTTP或各种各样的RPC协议）相互调用这些接口，从而组织成整个完整的软件系统。
微服务带来了很多好处：
整个业务系统“高内聚，低耦合”。不同模块只需要维护好对外的接口即可，对内完全是自治的。这给整个软件系统的迭代更新带来了极大的便利。比如，可以根据需要很方便地增减不同模块等等。 不同模块相互独立，其之间的沟通交流一般使用的是基于HTTP的与编程语言和编程框架无关的协议。这就使得同一个软件系统内部的不同微服务模块可以交给不同团队开发，不同团队可以根据自身的技术积累，或者当前模块的特点，使用不同的编程语言和框架来实现。 不同微服务模块的部署是相互独立的。这就意味着，可以根据需要调整不同模块部署的实例个数，而无需调整整个软件系统的部署情况，从而可以充分利用硬件资源。 微服务架构的上述特点很适合互联网业务敏捷开发、快速迭代的工作方式。 不难发现，微服务的特点和容器的优势有很大的重合点，容器非常适合用来作为微服务的实现方式。即，对每个模块构建一个或多个镜像，然后以部署容器的方式部署每个微服务模块。事实上，我们当前使用的各个大厂的主要业务都是跑在容器里面的。“微服务化”和“容器化”也基本成为了同义词。
容器管理与云 # 当前大部分互联网公司的业务的部署都是以容器的方式进行的。整个软件系统被拆成一个个微服务模块，每个微服务的实例都是一个容器。这些成千上万的容器翱翔在以数以万计的服务器组成的大规模集群的资源池中。容器定义了新时代的云。而所谓的“上云”，也基本意味着“将应用以容器方式进行部署和管理”。
随着容器数量的扩大，容器管理问题也逐渐凸显出来。试想，在容器数量很少时，你可以在自己的机器上手动使用docker命令开启或关闭容器。但当容器数量数以万计时，手动操作的成本就会迅速增加，因为：
即使每个容器因为各种各样的原因崩溃的概率很低，但乘以一个很大的容器总数，就会使“每时每刻都会有若干容器挂掉”变成大概率事件。为了保证业务的正常运行，必须能够即使发现这些崩溃的容器，并将它们重新启动。 在业务迭代时，经常需要更新容器的镜像。这意味着，我们必须能够在数以万计的容器中，找到先前版本的所有容器实例，并将它们关闭移除，然后启动新版本镜像的容器。 集群中的各个机器的状态可能不同（集群可能是异构的），为了充分发挥硬件资源的能力，必须能够即使根据不同机器的状态（空闲与否）和容器占用资源的情况，将容器调度到不同机器上运行。 不仅如此，随着单纯的容器化本身只是一种“理想的愿景”，有很多实际问题需要考虑：
前面我们提到，微服务的各个模块之间需要相互调用，这也意味着，不同容器之间需要相互交换信息，那么如何定位不同的容器、容器之间以怎样的方式发送和接收消息就成为一个非常重要的问题。 容器本身是“一次性”的，它的存储相关工作一般都交给数据卷来保存。不仅如此，数据对任何业务来讲都是最宝贵的资源，为了保证高可用，数据卷的管理必须考虑备份、容灾等。当容器数量增大时，数据卷的管理将变得非常复杂。 围绕这上述这些实际生产中的问题，很多科技公司都积极尝试并给出了自己的解决方案，但最终还是Google开源的Kubernetes笑到了最后，并已经在当下成为了分布式容器管理和容器编排的事实标准。而当下繁荣的云原生生态，也正是以容器和Kubernetes为基石，围绕它们构建起来的。
如果同学们对云计算感兴趣，可以去关注一下 CNCF（云原生计算基金会），它是Linux基金会的一部分，收录了大量云计算方面的开源项目，很多国内外大厂都是它的会员，同时也会给它捐献自己的云计算方面的开源项目，在 这里你可以看到CNCF的全景图。CNCF每年都会举办很多面向学生的开源项目活动，是一个接触并深入云计算领域的非常不错的窗口，感兴趣的同学可以多留意相关信息（比如各个大厂的云原生公众号，CNCF在国内的公众号等）。
课程设计内容 # 相信大家都上过软件学院的软件工程这门课。课程的大作业一般都需要完成做一次完整的软件开发，最终一般都需要提交源代码和相关文档等。但这门课的作业检查是非常痛苦的。不同小组使用的编程语言、编程框架及其相应的版本都不一而同。助教或教师如果想实际检查源代码的正确性（即能正确编译并在部署后能呈现出你文档中描述的那种效果）是非常困难的。
因此，请以软件学院为样本，结合容器技术，设计这样一个Web应用，教师或助教部署作业任务后，学生提交源代码和必要的编译部署选项（比如编译脚本、部署参数等）；教师或助教在学生提交完成后，只需要在系统中点击“编译”和“部署”按钮，就可以完成学生作品的部署流程，并观察到学生作品的运行效果。
以上只是对系统的笼统描述，有很多细节需要考虑：
软院云平台现有课程管理、实验管理、提交作业功能，如何将这些现有功能与新系统联动起来？ 学生提交作业时使用什么方式？直接提交源代码压缩包，还是给出一个代码托管地址？有自己的代码托管平台BuGit，如果将新系统与其联动起来？ 学生在完成作业后，提交代码前，很可能也需要自己在系统上尝试编译部署进行自测，以保证自己代码的运行效果与本地测试的效果相同。 （可选）大多数情况下，学生在完成作业时，都使用版本控制系统（如Git等）来管理代码。学生很可能需要在每次提交代码时能验证本次所提交的代码没有破坏之前的功能。即，系统应该可以在每次学生提交新代码（如果使用Git进行管理的话，就是在每次提交新commit时）时自动拉取学生代码，或者运行代码库的单元测试，或者进行编译和部署，并将结果展示出来。熟悉 GitHub Actions和 CI/CD的同学应该很容易理解这里在说什么。 本次课程设计并不需要大家真正实现这一系统，而是要编写文档，描述：
对上述场景进行需求分析，可以使用用例图等形式描述系统中包含哪些角色，每个角色应该有怎样的功能。请大家重视这一部分的工作，这是你接下来设计系统的重要前提。 描述系统的设计结构，可以使用原型图、架构图、流程图等形式，说明系统从教师或助教部署作业，到教师或助教看到学生的作业效果这一端到端的流程是怎样工作的。并请结合一个典型的作业类型（例如，一个包含了前端、后端和数据库的课程作业），来举例描述系统的工作流程。 描述技术选型，描述计划使用哪些关键技术，并且这些技术是怎样为最终系统功能服务的。</description></item><item><title>Kubernetes综合实验</title><link>https://scs.buaa.edu.cn/doc/cloud-labs/cloud/kube-single-3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://scs.buaa.edu.cn/doc/cloud-labs/cloud/kube-single-3/</guid><description>Kubernetes综合实验 # 实验目的 # 了解Kubernetes的各种特性 掌握Kubernetes的常用功能 注意事项
本次分配的机器的账户和密码为： buaa: &amp;amp;shieshuyuan21 为了避免权限问题，建议切换到root账户操作：
首先使用sudo passwd root为root账户设置密码 然后使用sudo su命令切换到root账户 务必首先修改机器的root和buaa账户的密码
请务必阅读 虚拟机使用说明。
分配的虚拟机中，已经安装了Docker，无需重复安装。
背景 # 上学期的云计算课中，我们主要了解了什么是容器，以及目前最流行的容器运行时和容器管理工具Docker；并且在此过程中体会了容器技术给软件开发和部署带来的极大的便利性。
但到此为止，我们对容器的使用和管理依旧处于非常“手工”的状态，难以胜任实际生产环境中对容器管理的要求。在实际生产环境中，
通常一个应用包含多个容器；即，一个应用的部署，需要按照一定的顺序启动多个容器。例如，即便是一个最简单的前后端应用，我们也需要依次启动三个容器：数据库容器（例如一个MySQL容器）、后端应用容器、前端应用容器（通常是一个Nginx容器）。特别是在微服务场景中，后端可能涉及到几十个微服务模块，每个模块都对应着一个容器，不同服务之间又有复杂的依赖调用关系。 每个类别的服务通常会有多个容器实例。对于一些负载较高的服务，通常会部署多个相同的容器实例达到负载均衡的效果，从而提高服务整体的吞吐量。 容器是不稳定的，随时可能会因为各种各样的原因挂掉，因此，需要时刻监控容器的状态，在它挂掉的时候及时重新启动服务，保证服务整体的高可用。 大部分应用都是分布式的。即，一个应用中的不同服务是部署在不同机器上的，即使是一个服务的不同实例往往也会部署在多个机器上。如何在多台机器上做好资源（内存、CPU、磁盘）的负载均衡（即，避免出现某些机器负载过高的同时，其他机器负载空闲的情况）也是棘手的问题。 如果仅靠我们已经学到的几个docker命令显然是难以完成上述任务的。这就需要一个专门的容器编排调度工具帮我们处理这些事情。自Docker兴起后，很多厂商都进入该领域并推出了自己的容器编排调度解决方案，例如Docker Swarm、Mesos等，都想在新兴的容器市场中分一杯羹，但最终Kubernetes笑到了最后，并且作为CNCF的毕业项目，成为了当下容器编排调度领域的事实标准。本次实验我们就来认识一下Kubernetes，学习并实践其中一些基本概念。
Kubernetes以其复杂难懂著称，在本次实验中，我们主要学习其中最基本的部分，培养大家对Kubernetes的感性认识，帮助大家开始入门云计算领域。
初识Kubernetes # Kubernetes简介 # Kubernetes在希腊语中的含义是船长/领航员，这个名字生动地体现了它在容器集群管理中的作用——调度和监控全局的集装箱（container，容器）。由于Kubernetes这个单词太长，人们通常会用k8s来作为简称（Kubernetes的首尾两个字母之间正好有8个字母）。
请始终记住，Kubernetes和Docker之类的容器运行时不是互相替代的关系，也不是包含与被包含的关系，而是互补的关系。Kubernetes仅仅是一个容器编排和调度工具，其必须运行在“容器运行时（container runtime）”之上。它能做的仅仅是接收用户的命令，然后通知其下层的容器运行时做具体的工作。
上图可以看出，在之前，我们是直接通过Docker命令行或Docker HTTP接口来与Docker容器运行时通信，控制其构建镜像、推送或拉取镜像、启动或停止容器，等等。
而现在，我们可以通过Kubernetes的命令行工具（即Kubectl）或Kubernetes的HTTP接口来控制Kubernetes，然后，Kubernetes会根据我们发出的命令，“翻译”成对应的Docker容器运行时的调用，从而控制Docker容器运行时构建镜像、推送或拉取镜像、启动或停止容器等等。
另外，请注意，Kubernetes是一个非常模块化的系统，它定义了一套“容器运行时接口（CRI）”，凡是实现了这套接口的容器运行时都可以作为Kubernetes运行容器的后端。目前比较流行的有Containerd和CRI-O，实际上，从1.20版本开始，Kubernetes官方已经弃用Docker引擎作为容器运行时。
在本次实验中，为了前后知识的连贯性，我们依旧选择使用Docker作为Kubernetes的容器运行时。
创建Kubernetes集群 # 在Kubernetes官网的 Get Started中，分别给出了面向个人初学者的学习测试环境和一线生产环境的若干Kubernetes集群部署方法。对于生产环境， Kubernetes官方推荐使用kubeadm来启动集群。但实际上，kubeadm对非专业的运维，特别是初学者来说并不十分友好（需要用户事先完成对主机的一系列配置，如开放防火墙端口、关闭swap、安装容器运行时等），再加上国内特殊的网络环境（kubeadm默认会从gcr.io拉取启动Kubernetes所需的系统镜像），因此不推荐初学者直接使用kubeadm启动集群。
云计算生态非常繁荣，社区中已经有很多成熟的工具帮助用户快速启动一个标准的Kubernetes集群用于学习、测试等目的。本实验文档分别针对集群版和本地版提供创建Kubernetes集群的选项，供大家参考和使用。
集群版 # 推荐使用此种方式创建集群，这样有利于在后续章节中学习和实践Kubernetes“集群”的相关特性。如确实有问题，可以切换到个人电脑上使用“单机版”的方式。
在本次实验中，我们将部署一个简单的 k3s（注意，不是“k8s”哦！）集群。k3s是通过CNCF认证的Kubernetes的一个发行版，是基于上游的“原生”的Kubernetes的代码进一步构建的。k3s和Kubernetes的关系可以简单类比为Ubuntu、CentOS等于Linux之间的关系。你可以在这里找到k3s官方维护的 k3s的中文文档。
实际上，还有很多其他的Kubernetes发行版，比如k0s之类的。只不过k3s的中国化做得非常好，在国内的网络环境下使用非常便利，也有大量的资料可以使用，所以我们选用其作为本次实验的主要工具。当然，不同Kubernetes发行版之间存在着各种各样的差异，但这并不影响我们学习Kubernetes的基础知识。
准备一台能够连接互联网的Linux机器。如果你选择使用软院云平台分配的机器，可以直接进行下一步；否则，请查看 安装要求，确保你的机器满足其中所述条件。
确保机器已经安装Docker，并且其版本高于或等于19.03，可以使用docker info命令验证。如果你使用的是软院云平台分配的机器，可直接进行下一步；否则，请注意检查Docker是否正确安装，并且是否正确配置Docker Registry镜像地址，以保证可以顺利从docker.io中拉取镜像。（当然，如果你已经比较熟悉Kubernetes，可以忽略此步骤，选择使用k3s默认集成安装的containerd作为容器运行时。）
保证你的机器已经连接互联网。
切换到root用户（如果你觉得root操作危险，请保证自己有足够的能力使用普通用户权限完成所有操作），执行以下命令以初始化一个k3s的master节点（当前不理解什么是“master节点”没有关系，在后续章节中我们会进行详细介绍）：
curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -s - --docker 如果你选择使用containerd作为容器运行时，请去除上述命令中的--docker参数。</description></item><item><title>自动构建与部署</title><link>https://scs.buaa.edu.cn/doc/02_bugit/build_deploy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://scs.buaa.edu.cn/doc/02_bugit/build_deploy/</guid><description>自动构建与部署 # 原理 # 本质上，自动构建与部署的过程是，系统根据用户提供的包含在代码仓库中的配置文件，将代码编译成一个OCI规范的镜像，然后上传到镜像中心，最后通知Kubernetes集群拉取镜像运行，以对外提供可用服务。
自动构建与部署的几个步骤：
用户编写配置合法的配置文件，并包含在代码仓库的根目录中。
用户触发自动构建与部署。目前支持自动监听代码推送（git push）动作，和在前端手动点击按钮触发。
系统拉取用户指定的仓库的指定的某次提交的代码，并根据指定的Dockerfile进行镜像构建。
系统将构建完成的镜像将推送到镜像中心（harbor.scs.buaa.edu.cn）。
系统通知Kubernetes拉取镜像，并部署之。
配置文件 # 配置文件一共包含两个：Dockerfile 和 .bugit.yaml。
Dockerfile # Dockerfile用来描述该代码仓库希望被如何编译和打包成一个OCI镜像。具体的编写规则可以参考 Dockerfile Reference。
.bugit.yaml # .bugit.yaml是一个YAML文件（名称.bugit.yml也是合法的，并且请注意文件名最前面那个.）。它是对整个构建和部署过程的描述。
下面是一个.bugit.yaml文件支持的全部指令的示例（请注意缩进）。
下方示例中，提到的非必需字段，都可以在.bugit.yaml省略不写。 # 必需字段。表示当前的.bugit.yaml 所适用的构建与部署流程的版本号，目前仅支持 0.0.1 version: 0.0.1 # on 字段中的内容用来表示在哪个分支发生什么事件时，自动启动构建与部署流程 # 该字段中可以包含若干组内容，每一组的 key （比如，下方示例中的 main 和 master） 都是分支名称，其 value （比如下方示例中的 [push]）是一个数组，表示希望系统监听哪些事件的发生 # 比如下面的示例就表示，希望系统在远程仓库的 main 分支和 master 分支发生代码推送事件（git push）时，自动启动构建与部署流程 # 如果希望开启“自动”构建与部署的功能，那么该字段是必需的 on: main: [&amp;#34;push&amp;#34;] master: [&amp;#34;push&amp;#34;] # 必需字段。build 字段用来描述如何系统如何构建OCI镜像 build: name: build-1 # 必需。名称标识，目前没有太大意义。可以是任意字符串，但请不要带空格 type: docker # 必需。构建的类型，目前仅支持docker docker_tag: simple # 非必需。表示希望给构建好的字段加的额外tag dockerfile: .</description></item><item><title>虚拟机使用说明</title><link>https://scs.buaa.edu.cn/doc/01_common/virtual_machine_help/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://scs.buaa.edu.cn/doc/01_common/virtual_machine_help/</guid><description>虚拟机使用说明 # 连接虚拟机 # Linux系统 # 首先从云平台中获取虚拟机的IP和登录名，之后即可在本地通过任意ssh客户端登录。
MacOS 使用系统自带的Terminal.app登录即可。
为了更好的使用体验，推荐使用 iterm2登录。
当然，你也可以使用 termius进行多个ssh连接的管理。
Linux 如果你是Linux Desktop用户，那么你肯定已经有了自己喜爱的终端模拟器，此处不再赘述。 Windows 一般来讲，Windows 10（及以上）自带的cmd.exe都自带ssh client，打开cmd后直接ssh foo@x.x.x.x即可登录。
为了更好的使用体验，推荐下载使用 Windows Terminal。
当然，你也可以使用 termius或者其他工具（如 Xshell等）进行多个ssh连接的管理。
校外访问 || 浏览器访问 联网 # Linux系统 # 可以依次尝试以下两种方式。
校园网登录脚本 # 这里推荐使用buaalogin（即 srun）。
2022年8月开始分配的虚拟机默认已经安装了buaalogin工具，可使用which buaalogin验证其是否存在，如果存在，则可以跳过此步骤。 下载并安装登录工具：
sudo wget https://scs.buaa.edu.cn/scsos/tools/linux/buaalogin -O /usr/local/bin/buaalogin sudo chmod +x /usr/local/bin/buaalogin 配置校园网登录使用的用户名和密码：
buaalogin config 登录校园网：
buaalogin login 登出校园网：
buaalogin logout wukuard 服务 # 鉴于校网络中心的某些限制，上述联网方式可能在某短时间内无法使用，这里特别给出软院信息化小组的基于 Wireguard的曲线救国方案。其本质上是将虚拟机加入一个 wireguard虚拟内网，然后覆盖默认路由指向一个可以联网的内网机器，从而实现虚拟机本身与互联网的联通。
2022年8月开始分配的虚拟机默认配置好了 wukuard服务，可使用systemctl status wukuard验证之，如果运行正常，则可跳过下述的各个步骤，直接进行最后的配置hostname即可。 请注意，以下步骤是针对Debian系发行版（包括Debian、Ubuntu等）给出的，其他发行版请自行对照着修改命令。 首先需要安装wireguard-tools（这里需要短暂联网，但完整整个步骤之后就不需要了）：</description></item><item><title>FAQ</title><link>https://scs.buaa.edu.cn/doc/cloud-labs/cloud/faq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://scs.buaa.edu.cn/doc/cloud-labs/cloud/faq/</guid><description> FAQ #</description></item></channel></rss>